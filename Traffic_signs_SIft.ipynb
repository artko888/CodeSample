{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import pandas as pd\n",
    "#import matplotlib\n",
    "#matplotlib.use(\"TkAgg\")  # Do this before importing pyplot!\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar=np.arange(62)\n",
    "fldrs=[]\n",
    "for i in range(10):\n",
    "    fldrs.append(str('Training/'+'0000'+str(ar[i])))\n",
    "for i in range(10,62):\n",
    "    fldrs.append(str('Training/'+'000'+str(ar[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#paths=glob.glob('./'+newpath+'/*.csv')\n",
    "def read_image_paths(newpath):\n",
    "    try:\n",
    "        if os.path.exists(newpath):\n",
    "           # print('\\n Such path exists \\n')\n",
    "            paths=glob.glob(newpath+'/*.ppm')\n",
    "            #print(paths)\n",
    "        else:\n",
    "            print('Path does not exist') \n",
    "        return paths\n",
    "        #return {i:pd.read_csv(i,index_col=['date'],parse_dates=['date']) for i in paths},paths #an error occurs when index_col is wrong \n",
    "    except Exception:\n",
    "        print('Error reading stock data')\n",
    "        return -1\n",
    "def read_image_info(newpath):\n",
    "    try:\n",
    "        if os.path.exists(newpath):\n",
    "            #print('\\n Such path exists \\n')\n",
    "            paths=glob.glob(newpath+'/*.csv')\n",
    "            #im_paths=glob.glob(newpath+'/*.ppm')\n",
    "            #print(paths)\n",
    "        else:\n",
    "            print('Path does not exist') \n",
    "        df=pd.read_csv(paths[0],sep=';',header=0)\n",
    "        #df['Path']=pd.Series(im_paths)\n",
    "        return df#pd.read_csv(paths[0],sep=';',header=0) \n",
    "    except Exception:\n",
    "        print('Error reading stock data',Exception)\n",
    "        return -1\n",
    "def read_all_image_info(fldrs):\n",
    "    # it will be better to process exceptions\n",
    "    #paths=[]\n",
    "    res=read_image_info(fldrs[0])\n",
    "    res['Path']=pd.Series(add_full_path(fldrs[0],res)) ########################################################Added full path\n",
    "    for i in range(len(fldrs)-1):\n",
    "        df2=read_image_info(fldrs[i+1])\n",
    "        df2['Path']=pd.Series(add_full_path(fldrs[i+1],df2))#############################################Added full path\n",
    "        frames=[res,df2]\n",
    "        res=pd.concat(frames)\n",
    "        res=res.reset_index(drop=True)       \n",
    "    return res\n",
    "\n",
    "def to_gray(color_img):\n",
    "    gray=cv2.cvtColor(color_img,cv2.COLOR_BGR2GRAY)\n",
    "    return gray\n",
    "\n",
    "def gen_sift_features(gray_img):\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "    # kp is the keypoints\n",
    "    #\n",
    "    # desc is the SIFT descriptors, they're 128-dimensional vectors\n",
    "    # that we can use for our final features\n",
    "    kp, desc = sift.detectAndCompute(gray_img, None)\n",
    "    return kp, desc\n",
    "\n",
    "def show_sift_features(gray_img, color_img, kp):\n",
    "    return plt.imshow(cv2.drawKeypoints(gray_img, kp, color_img.copy()))\n",
    "def concat_frames(df1,df2):\n",
    "    frames=[df1,df2]\n",
    "    res=pd.concat(frames)\n",
    "    res=res.reset_index(drop=True)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proper_sized_image(im):\n",
    "    h,w=im.shape #first height second width\n",
    "    if w>minw:\n",
    "        im=cv2.resize(im,(minw,h))\n",
    "    h,w=im.shape\n",
    "    if h>minh:\n",
    "        im=cv2.resize(im,(w,minh))\n",
    "    h,w=im.shape\n",
    "    if minw>w or minh>h:\n",
    "        im=cv2.resize(im,(minw, minh),interpolation=cv2.INTER_NEAREST)        \n",
    "    return im\n",
    "def read_image(newpath):\n",
    "        try:\n",
    "            if os.path.exists(newpath):\n",
    "                1==1\n",
    "                # print('\\n Such path exists \\n')\n",
    "            else:\n",
    "                print('Path does not exist') \n",
    "            image=cv2.imread(newpath)\n",
    "            gray=to_gray(image)\n",
    "            #image=proper_sized_image(image)\n",
    "            gray=proper_sized_image(gray)\n",
    "            #gray = cv2.GaussianBlur(gray, (3, 3), 0)\n",
    "            return image ,gray\n",
    "        except Exception:\n",
    "            print('Error reading stock data')\n",
    "            return -1\n",
    "def im_show(im):\n",
    "    cv2.imshow('image',im)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "def int_ar(ar):\n",
    "    mas=list(map(lambda x: int(x), ar))\n",
    "    return mas\n",
    "def label_from_path(path):\n",
    "    return info_all[info_all['Path']==path]['ClassId'].tolist()[0]\n",
    "def first_picture__from_label(df,label):\n",
    "    try:\n",
    "        path=df[df['ClassId']==label]['Path'].tolist()[0]\n",
    "        im=read_image(path)\n",
    "        im_show(im[1])\n",
    "        return 0\n",
    "    except Exception:\n",
    "        return -1\n",
    "def add_full_path(folder,df):\n",
    "    return list(map(lambda x:str(folder)+'/'+str(x),df['Filename'].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define functions to create bag of words(to merge sift descriptors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess1_image(path):\n",
    "    image=read_image(path)\n",
    "    im_kp, im_desc=gen_sift_features(image[1])\n",
    "    return im_desc\n",
    "def preprocess_images(paths):\n",
    "    #labels=[]\n",
    "    i=0\n",
    "    for p in paths:\n",
    "        if i==0:\n",
    "            bag=preprocess1_image(p)\n",
    "            #print(len(bag))\n",
    "            i+=1\n",
    "        else:\n",
    "            #try: \n",
    "            bag=np.vstack((bag,preprocess1_image(p)))\n",
    "            #print(len(bag))\n",
    "    return bag\n",
    "           # except Exception:\n",
    "            \n",
    "            #labels.append(label_from_path(p))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster(bag_of_words,n_clusters):\n",
    "    try:\n",
    "        if len(bag_of_words)>n_clusters:\n",
    "            kmeans=KMeans(n_clusters=n_clusters,random_state=0).fit(bag_of_words)\n",
    "            return kmeans # define only for 1?tures1=kmeans.labels_\n",
    "        else:\n",
    "            print('not enough features to classify: ',len(bag_of_words))\n",
    "    except Exception:\n",
    "        print(\"bag of words exception occured: \",Exception)\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict histogram for an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_histogram(kmeans,image_path,n_clusters):\n",
    "    litter,image=read_image(image_path)\n",
    "    kp,image_descriptors=gen_sift_features(image)\n",
    "    set_of_clusters=kmeans.predict(image_descriptors)\n",
    "    hist,bins=np.histogram(set_of_clusters,n_clusters)\n",
    "    #plt.hist(set_of_clusters,bins=n_clusters)\n",
    "    return hist\n",
    "def images_to_histograms(kmeans,paths,n_clusters):\n",
    "    try:\n",
    "        hists=[]\n",
    "        labels=[]\n",
    "        for p in paths:\n",
    "            hists.append(image_histogram(kmeans,p,n_clusters))\n",
    "            labels.append(label_from_path(p))\n",
    "        return np.array(hists) , np.array(labels)\n",
    "    except Exception:\n",
    "        print('histograms exception occured: ',Exception)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125 110\n"
     ]
    }
   ],
   "source": [
    "info_all=read_all_image_info(fldrs)\n",
    "minh=int(round(info_all['Height'].mean()))\n",
    "minw=int(round(info_all['Width'].mean()))\n",
    "print (minw,minh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# testing image from label function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_picture__from_label(info_all,61)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sift application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make small set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_small_set(inform,l1,l2):\n",
    "    return concat_frames(inform[inform['ClassId']==l1],inform[inform['ClassId']==l2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_ar=make_small_set(info_all,39,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_of_words=preprocess_images(first_ar['Path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2  1  0  0  2  1  0  1  0  0  0  3  1  1  4  0  2  0  1  0  0  2  1  1\n",
      "  1  1  0  1  1  0  0  1  1  0  1  0  2  0  2  0  1  1  1  1  1  0  1  0\n",
      "  0  0  1  1  2  1  0  0  0  1  1  8  0  1  0  0  0  0  0  0  2  0  2  1\n",
      "  1  1  1  0  0  0  0  1  2 17  0  2  4  3  0  1  0  1  2  1  0  0  0  2\n",
      "  0  0  0  0  0  2  0  0  3  1  1  1  1  1  0  0  0  0  0  2  0  0  1  2\n",
      "  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  1  0  0  0  1  1\n",
      "  0  0  2  0  0  2]\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n=150\n",
    "kmeans=cluster(bag_of_words,n)\n",
    "print(image_histogram(kmeans,first_ar['Path'].tolist()[0],n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "histograms,labels=images_to_histograms(kmeans,first_ar['Path'].tolist(),n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "209"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(histograms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test data and labeling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=histograms\n",
    "y=labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39\n",
      " 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39  2\n",
      " 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42,stratify=y)\n",
    "clf = SVC(gamma='auto')\n",
    "clf.fit(X_train, y_train)\n",
    "pred=clf.predict(X_test)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9565217391304348"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define function model_SIFT_SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_for_classification(first_ar,n):\n",
    "    bag_of_words=preprocess_images(first_ar['Path'])\n",
    "    kmeans=cluster(bag_of_words,n)\n",
    "    X,y=images_to_histograms(kmeans,first_ar['Path'].tolist(),n)  \n",
    "    return X,y\n",
    "def model_SIFT_SVC(first_ar,n):\n",
    "    X,y=prepare_data_for_classification(first_ar,n)\n",
    "    #bag_of_words=preprocess_images(first_ar['Path'])\n",
    "    #kmeans=cluster(bag_of_words,n)\n",
    "    #X,y=images_to_histograms(kmeans,first_ar['Path'].tolist(),n)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42,stratify=y)\n",
    "    clf = SVC(gamma='auto')\n",
    "    clf.fit(X_train, y_train)\n",
    "    pred=clf.predict(X_test)\n",
    "    acc_score=accuracy_score(y_test,pred)\n",
    "    print(acc_score)\n",
    "    return acc_score,clf   \n",
    "def optimize_n_clusters(first_ar,nmin,nmax,step=15):\n",
    "    mscore=0\n",
    "    i=nmin\n",
    "    m_n_clusters=i\n",
    "    while i in range(nmin,nmax):\n",
    "        score,classifier=model_SIFT_SVC(first_ar,i)\n",
    "        if score>mscore:\n",
    "            mscore=score\n",
    "            m_n_clusters=i\n",
    "        i+=step\n",
    "    return m_n_clusters,mscore   \n",
    "def make_df_several_labls(inform,labels):# it seems to work well\n",
    "    df=inform[inform['ClassId']==labels[0]]\n",
    "    for i in range(1,len(labels)):\n",
    "        df=concat_frames(df,inform[inform['ClassId']==labels[i]])\n",
    "    return df    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# let's find out what classes are most common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[22, 32, 38, 61, 40]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info_all['ClassId'].value_counts()[:5].index.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main part of the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8427947598253275\n",
      "Wall time: 7min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n=200\n",
    "#2 classes\n",
    "first_ar=make_small_set(info_all,32,22)\n",
    "res=model_SIFT_SVC(first_ar,n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=200\n",
    "labels=info_all['ClassId'].value_counts()[:5].index.tolist() #if labels are 0,4,6 the best n=200\n",
    "data=make_df_several_labls(info_all,labels)\n",
    "#first_ar=make_small_set(info_all,32,28)#22,32 (39,7) n=250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6\n",
      "Wall time: 19min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "res=model_SIFT_SVC(data,n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
